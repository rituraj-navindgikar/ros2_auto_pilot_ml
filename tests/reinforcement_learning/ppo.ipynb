{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO - Proximal Policy Optimization \n",
    "State (Observations): Your LaserScan data (scan_0 to scan_359)\n",
    "\n",
    "Actions: Continuous cmd_vel values (linear_x and angular_z)\n",
    "\n",
    "Reward:\n",
    "  -  Positive: For reaching goals or following a clear path\n",
    "  -  Negative: For collisions, inefficiencies, or leaving boundaries\n",
    "\n",
    "Done Signal: Indicates when an episode ends (e.g., collision or reaching the goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaserScanEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(LaserScanEnv, self).__init__()\n",
    "        \n",
    "        # Observation space\n",
    "        self.observation_space = spaces.Box(low=0, high=10, shape=(360,), dtype=np.float32)\n",
    "        \n",
    "        # Action space\n",
    "        self.action_space = spaces.Box(low=np.array([-1.0, -1.0]), high=np.array([1.0, 1.0]), dtype=np.float32)\n",
    "        \n",
    "        # Initial state\n",
    "        self.state = np.random.uniform(0, 10, size=(360,))\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Ensure reproducibility by setting the random seed\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        self.state = np.random.uniform(0, 10, size=(360,)).astype(np.float32)  # Cast to float32\n",
    "        self.done = False\n",
    "        info = {}  # Additional info can be added here if needed\n",
    "        return self.state, info  # Return a tuple (obs, info)\n",
    "\n",
    "    def step(self, action):\n",
    "        # Apply action and update state\n",
    "        self.state = np.random.uniform(0, 10, size=(360,)).astype(np.float32)  # Ensure dtype is float32\n",
    "        reward = self._calculate_reward(action)\n",
    "        \n",
    "        # Split the \"done\" condition into `terminated` and `truncated`\n",
    "        terminated = self._check_done()  # E.g., collision or reaching goal\n",
    "        truncated = False  # For now, we won't handle time limits, so this is always False\n",
    "        \n",
    "        info = {}  # Additional information (if any)\n",
    "        return self.state, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        # reward function\n",
    "        if self.done:\n",
    "            return -100 if self.done else 100\n",
    "        return 1.0 - np.abs(action[0])  # Penalty \n",
    "    \n",
    "    def _check_done(self):\n",
    "        return np.random.choice([True, False], p=[0.1, 0.9]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "env = LaserScanEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.87     |\n",
      "|    ep_rew_mean     | 3.68     |\n",
      "| time/              |          |\n",
      "|    fps             | 3267     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.5       |\n",
      "|    ep_rew_mean          | 4.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2211       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01470397 |\n",
      "|    clip_fraction        | 0.0827     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.8       |\n",
      "|    explained_variance   | -0.0606    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.16       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0242    |\n",
      "|    std                  | 0.966      |\n",
      "|    value_loss           | 3          |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.32        |\n",
      "|    ep_rew_mean          | 3.72        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1982        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014649197 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | -0.0138     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.24        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    std                  | 0.95        |\n",
      "|    value_loss           | 4.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.3        |\n",
      "|    ep_rew_mean          | 4.48        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1846        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017423231 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | -0.0234     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.36        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 4.94        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.9        |\n",
      "|    ep_rew_mean          | 4.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1803        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019188732 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | -0.0288     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 6.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.57        |\n",
      "|    ep_rew_mean          | 4.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1772        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025550775 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | -0.0341     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.51        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 7.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11          |\n",
      "|    ep_rew_mean          | 4.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1761        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028427815 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.54       |\n",
      "|    explained_variance   | -0.0148     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.62        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 6.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.1        |\n",
      "|    ep_rew_mean          | 4.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1751        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021000292 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.5        |\n",
      "|    explained_variance   | -0.0192     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.05        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 0.836       |\n",
      "|    value_loss           | 7.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.8        |\n",
      "|    ep_rew_mean          | 4.83        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1743        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022153001 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | -0.035      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.85        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    std                  | 0.827       |\n",
      "|    value_loss           | 8.45        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.99        |\n",
      "|    ep_rew_mean          | 4.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1740        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028652817 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | -0.0346     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.82        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    std                  | 0.806       |\n",
      "|    value_loss           | 7.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.35        |\n",
      "|    ep_rew_mean          | 4.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1736        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032123856 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.37       |\n",
      "|    explained_variance   | -0.0234     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.14        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    std                  | 0.788       |\n",
      "|    value_loss           | 8.03        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.74       |\n",
      "|    ep_rew_mean          | 4.64       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1728       |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03335233 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.32      |\n",
      "|    explained_variance   | -0.0269    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.5        |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0478    |\n",
      "|    std                  | 0.772      |\n",
      "|    value_loss           | 6.88       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.36       |\n",
      "|    ep_rew_mean          | 4.57       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1724       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03464732 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.28      |\n",
      "|    explained_variance   | -0.0171    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.7        |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0429    |\n",
      "|    std                  | 0.754      |\n",
      "|    value_loss           | 6.96       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11          |\n",
      "|    ep_rew_mean          | 5.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1722        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039005257 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | -0.0237     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.58        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0505     |\n",
      "|    std                  | 0.74        |\n",
      "|    value_loss           | 9.33        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.9        |\n",
      "|    ep_rew_mean          | 6.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1721        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039011452 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | -0.00697    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.91        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    std                  | 0.723       |\n",
      "|    value_loss           | 9.82        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.5       |\n",
      "|    ep_rew_mean          | 5.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1719       |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04084321 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.13      |\n",
      "|    explained_variance   | -0.0101    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.96       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0539    |\n",
      "|    std                  | 0.7        |\n",
      "|    value_loss           | 10         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.61        |\n",
      "|    ep_rew_mean          | 4.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1718        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038751416 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | -0.00628    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.25        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    std                  | 0.689       |\n",
      "|    value_loss           | 9.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.7         |\n",
      "|    ep_rew_mean          | 4.99        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1718        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036263984 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | -0.017      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    std                  | 0.674       |\n",
      "|    value_loss           | 9.93        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.78        |\n",
      "|    ep_rew_mean          | 5.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1717        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040200606 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | -0.014      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.34        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    std                  | 0.663       |\n",
      "|    value_loss           | 9.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.97        |\n",
      "|    ep_rew_mean          | 4.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1713        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045643456 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | -0.0157     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.65        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    std                  | 0.648       |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.7        |\n",
      "|    ep_rew_mean          | 5.89        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1713        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052879766 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.0126     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.7         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.052      |\n",
      "|    std                  | 0.631       |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.8       |\n",
      "|    ep_rew_mean          | 5.92       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1711       |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05687577 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.85      |\n",
      "|    explained_variance   | -0.0111    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.04       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0518    |\n",
      "|    std                  | 0.611      |\n",
      "|    value_loss           | 10.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.3        |\n",
      "|    ep_rew_mean          | 5.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1710        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047664672 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -0.0113     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.12        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0488     |\n",
      "|    std                  | 0.603       |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.38        |\n",
      "|    ep_rew_mean          | 5.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1709        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043168236 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -0.00872    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.06        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    std                  | 0.597       |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.72        |\n",
      "|    ep_rew_mean          | 4.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1708        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047943033 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.02       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0516     |\n",
      "|    std                  | 0.594       |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.3       |\n",
      "|    ep_rew_mean          | 6.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1707       |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 31         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05636087 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.72      |\n",
      "|    explained_variance   | -0.0256    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.41       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0446    |\n",
      "|    std                  | 0.58       |\n",
      "|    value_loss           | 13.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.68       |\n",
      "|    ep_rew_mean          | 5.65       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1707       |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06639377 |\n",
      "|    clip_fraction        | 0.395      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.69      |\n",
      "|    explained_variance   | -0.00859   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.12       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0471    |\n",
      "|    std                  | 0.572      |\n",
      "|    value_loss           | 13.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.1       |\n",
      "|    ep_rew_mean          | 6.01       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1706       |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05574327 |\n",
      "|    clip_fraction        | 0.381      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.65      |\n",
      "|    explained_variance   | -0.0136    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.57       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0454    |\n",
      "|    std                  | 0.559      |\n",
      "|    value_loss           | 12         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.04       |\n",
      "|    ep_rew_mean          | 5.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1704       |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07104054 |\n",
      "|    clip_fraction        | 0.416      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.59      |\n",
      "|    explained_variance   | -0.011     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.27       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0508    |\n",
      "|    std                  | 0.542      |\n",
      "|    value_loss           | 12.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.3       |\n",
      "|    ep_rew_mean          | 6.92       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1702       |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07374087 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.54      |\n",
      "|    explained_variance   | -0.00631   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7          |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0509    |\n",
      "|    std                  | 0.528      |\n",
      "|    value_loss           | 12.7       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 10.4      |\n",
      "|    ep_rew_mean          | 6.58      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1700      |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 37        |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0758965 |\n",
      "|    clip_fraction        | 0.392     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.48     |\n",
      "|    explained_variance   | -0.00579  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.71      |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -0.0546   |\n",
      "|    std                  | 0.515     |\n",
      "|    value_loss           | 13.9      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.61       |\n",
      "|    ep_rew_mean          | 6.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1695       |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06417365 |\n",
      "|    clip_fraction        | 0.385      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.45      |\n",
      "|    explained_variance   | -0.00759   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.47       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0528    |\n",
      "|    std                  | 0.514      |\n",
      "|    value_loss           | 14.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.3        |\n",
      "|    ep_rew_mean          | 6.42        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1694        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.067589834 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -0.00549    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0524     |\n",
      "|    std                  | 0.508       |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.93       |\n",
      "|    ep_rew_mean          | 5.62       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1691       |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06283156 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.39      |\n",
      "|    explained_variance   | -0.00308   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.08       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0559    |\n",
      "|    std                  | 0.499      |\n",
      "|    value_loss           | 14.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.8       |\n",
      "|    ep_rew_mean          | 7.64       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1688       |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 42         |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08110327 |\n",
      "|    clip_fraction        | 0.404      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | -0.0318    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.9        |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    std                  | 0.493      |\n",
      "|    value_loss           | 11.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 7.99       |\n",
      "|    ep_rew_mean          | 5.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1678       |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07400149 |\n",
      "|    clip_fraction        | 0.394      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | -0.00472   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.72       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0504    |\n",
      "|    std                  | 0.486      |\n",
      "|    value_loss           | 16.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.99       |\n",
      "|    ep_rew_mean          | 5.74       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1663       |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07406895 |\n",
      "|    clip_fraction        | 0.391      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.3       |\n",
      "|    explained_variance   | -0.00997   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.23       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    std                  | 0.477      |\n",
      "|    value_loss           | 13.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.2       |\n",
      "|    ep_rew_mean          | 6.4        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1656       |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07223495 |\n",
      "|    clip_fraction        | 0.414      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | -0.00286   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.47       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0517    |\n",
      "|    std                  | 0.471      |\n",
      "|    value_loss           | 13.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.6       |\n",
      "|    ep_rew_mean          | 7.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1650       |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09627798 |\n",
      "|    clip_fraction        | 0.444      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | -0.0154    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.2        |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0443    |\n",
      "|    std                  | 0.461      |\n",
      "|    value_loss           | 14.1       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9.02      |\n",
      "|    ep_rew_mean          | 6.04      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1640      |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0879255 |\n",
      "|    clip_fraction        | 0.459     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.21     |\n",
      "|    explained_variance   | -0.00268  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.12      |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | -0.0402   |\n",
      "|    std                  | 0.461     |\n",
      "|    value_loss           | 16.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.95        |\n",
      "|    ep_rew_mean          | 6.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1636        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.100774705 |\n",
      "|    clip_fraction        | 0.452       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.00437    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.2         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    std                  | 0.455       |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.77       |\n",
      "|    ep_rew_mean          | 6.57       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1634       |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 52         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08953005 |\n",
      "|    clip_fraction        | 0.455      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | -0.00433   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.89       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0506    |\n",
      "|    std                  | 0.442      |\n",
      "|    value_loss           | 15.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.11       |\n",
      "|    ep_rew_mean          | 6.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1633       |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11248521 |\n",
      "|    clip_fraction        | 0.452      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | -0.00922   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.71       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0361    |\n",
      "|    std                  | 0.437      |\n",
      "|    value_loss           | 16.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.1       |\n",
      "|    ep_rew_mean          | 7.32       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1632       |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10626105 |\n",
      "|    clip_fraction        | 0.438      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | -0.00117   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.66       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0445    |\n",
      "|    std                  | 0.432      |\n",
      "|    value_loss           | 16.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.8       |\n",
      "|    ep_rew_mean          | 7.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1632       |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10208619 |\n",
      "|    clip_fraction        | 0.448      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | -0.00508   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.26       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0419    |\n",
      "|    std                  | 0.428      |\n",
      "|    value_loss           | 14.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.52       |\n",
      "|    ep_rew_mean          | 5.83       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1633       |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09220276 |\n",
      "|    clip_fraction        | 0.448      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | -0.00123   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.97       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0471    |\n",
      "|    std                  | 0.421      |\n",
      "|    value_loss           | 18.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.35       |\n",
      "|    ep_rew_mean          | 6.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1632       |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 58         |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12346883 |\n",
      "|    clip_fraction        | 0.454      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.999     |\n",
      "|    explained_variance   | -0.00786   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.31       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0573    |\n",
      "|    std                  | 0.416      |\n",
      "|    value_loss           | 15.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.29       |\n",
      "|    ep_rew_mean          | 6.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1632       |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11758368 |\n",
      "|    clip_fraction        | 0.465      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.97      |\n",
      "|    explained_variance   | -0.00292   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.51       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0495    |\n",
      "|    std                  | 0.409      |\n",
      "|    value_loss           | 17.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 7.68       |\n",
      "|    ep_rew_mean          | 5.28       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1632       |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 61         |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11595497 |\n",
      "|    clip_fraction        | 0.46       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.934     |\n",
      "|    explained_variance   | -0.00392   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.07       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0452    |\n",
      "|    std                  | 0.404      |\n",
      "|    value_loss           | 15         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7ad998d56f80>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(\"ppo_robot_navigation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: [778.79944]\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_util import DummyVecEnv\n",
    "env = DummyVecEnv([lambda: LaserScanEnv()])\n",
    "\n",
    "# Load the trained model\n",
    "model = PPO.load(\"ppo_robot_navigation\")\n",
    "\n",
    "# Test the model\n",
    "obs = env.reset()\n",
    "rewards = []\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)  # Predict action\n",
    "    obs, reward, done, info = env.step(action)  # Step through the environment\n",
    "    rewards.append(reward)  # Collect rewards\n",
    "    if done.any():  # VecEnv returns `done` as an array\n",
    "        obs = env.reset()\n",
    "\n",
    "# Print total rewards and metrics\n",
    "total_reward = sum(rewards)\n",
    "print(f\"Total Reward: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward per Episode: [8.033576]\n"
     ]
    }
   ],
   "source": [
    "# Track rewards for each episode\n",
    "episode_rewards = []\n",
    "current_reward = 0\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    current_reward += reward\n",
    "    if done.any():\n",
    "        episode_rewards.append(current_reward)\n",
    "        current_reward = 0  # Reset episode reward\n",
    "        obs = env.reset()\n",
    "\n",
    "# Calculate metrics\n",
    "average_reward = sum(episode_rewards) / len(episode_rewards)\n",
    "print(f\"Average Reward per Episode: {average_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.00%\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "total_episodes = 0\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if done.any():\n",
    "        total_episodes += 1\n",
    "        # Assume success if reward > threshold (e.g., 50 for reaching a goal)\n",
    "        if reward > 50:\n",
    "            success_count += 1\n",
    "        obs = env.reset()\n",
    "\n",
    "success_rate = success_count / total_episodes\n",
    "print(f\"Success Rate: {success_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import rclpy\n",
    "from sensor_msgs.msg import LaserScan\n",
    "from geometry_msgs.msg import Twist\n",
    "\n",
    "class RosLaserScanEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(RosLaserScanEnv, self).__init__()\n",
    "\n",
    "        # Initialize ROS node\n",
    "        rclpy.init_node(\"rl_environment\", anonymous=True)\n",
    "\n",
    "        # Publishers and Subscribers\n",
    "        self.pub_cmd_vel = rclpy.Publisher(\"/cmd_vel\", Twist, queue_size=10)\n",
    "        self.sub_scan = rclpy.Subscriber(\"/scan\", LaserScan, self.scan_callback)\n",
    "\n",
    "        # Observation space: LiDAR data (360 values)\n",
    "        self.observation_space = spaces.Box(low=0, high=10, shape=(360,), dtype=np.float32)\n",
    "\n",
    "        # Action space: cmd_vel (linear_x, angular_z)\n",
    "        self.action_space = spaces.Box(low=np.array([-1.0, -1.0]), high=np.array([1.0, 1.0]), dtype=np.float32)\n",
    "\n",
    "        # Initialize state and done flag\n",
    "        self.state = np.zeros(360, dtype=np.float32)\n",
    "        self.done = False\n",
    "\n",
    "    def scan_callback(self, msg):\n",
    "        # Update state with LaserScan data\n",
    "        self.state = np.array(msg.ranges, dtype=np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Reset the environment\n",
    "        self.done = False\n",
    "        rclpy.sleep(1)  # Allow sensors to stabilize\n",
    "        return self.state, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Publish action to /cmd_vel\n",
    "        cmd_vel = Twist()\n",
    "        cmd_vel.linear.x = action[0]\n",
    "        cmd_vel.angular.z = action[1]\n",
    "        self.pub_cmd_vel.publish(cmd_vel)\n",
    "\n",
    "        # Calculate reward\n",
    "        reward = self._calculate_reward(action)\n",
    "\n",
    "        # Check if episode is done\n",
    "        self.done = self._check_done()\n",
    "\n",
    "        return self.state, reward, self.done, False, {}\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        # Reward for smooth movement and avoiding collisions\n",
    "        return 1.0 - abs(action[0]) if not self.done else -100.0\n",
    "\n",
    "    def _check_done(self):\n",
    "        # Example condition: stop episode if too close to an obstacle\n",
    "        return np.min(self.state) < 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'rclpy' has no attribute 'init_node'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmonitor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Monitor\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Wrap the environment for RL training\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mDummyVecEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mMonitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRosLaserScanEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train PPO\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:30\u001b[0m, in \u001b[0;36mDummyVecEnv.__init__\u001b[0;34m(self, env_fns)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: List[Callable[[], gym\u001b[38;5;241m.\u001b[39mEnv]]):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs \u001b[38;5;241m=\u001b[39m [_patch_env(fn()) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m env_fns]\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env\u001b[38;5;241m.\u001b[39munwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs])) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of creating different objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:30\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: List[Callable[[], gym\u001b[38;5;241m.\u001b[39mEnv]]):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs \u001b[38;5;241m=\u001b[39m [_patch_env(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m env_fns]\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env\u001b[38;5;241m.\u001b[39munwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs])) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of creating different objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[68], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmonitor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Monitor\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Wrap the environment for RL training\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: Monitor(\u001b[43mRosLaserScanEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train PPO\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[67], line 13\u001b[0m, in \u001b[0;36mRosLaserScanEnv.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28msuper\u001b[39m(RosLaserScanEnv, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize ROS node\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mrclpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_node\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrl_environment\u001b[39m\u001b[38;5;124m\"\u001b[39m, anonymous\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Publishers and Subscribers\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_cmd_vel \u001b[38;5;241m=\u001b[39m rclpy\u001b[38;5;241m.\u001b[39mPublisher(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/cmd_vel\u001b[39m\u001b[38;5;124m\"\u001b[39m, Twist, queue_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'rclpy' has no attribute 'init_node'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Wrap the environment for RL training\n",
    "env = DummyVecEnv([lambda: Monitor(RosLaserScanEnv())])\n",
    "\n",
    "# Train PPO\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=100000)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"ppo_robot_navigation\")\n",
    "#s\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
